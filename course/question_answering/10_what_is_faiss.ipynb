{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is FAISS\n",
    "\n",
    "**Facebook AI Similarity Search** (FAISS) is a more efficient implementation of *similarity searching* that can be used to efficiently scale to millions of samples without issue.\n",
    "\n",
    "Similarity search typically works by creating vectors from data, these vectors are represented as *points* in a highly-dimensional space (so like points in a 3D chart, but with 100+ dimensions).\n",
    "\n",
    "We can then introduce a new vector and search for similiar entries by comparing where it is within that highly dimensional space to all of the other vectors, often using Euclidean distance or cosine similarity calculations.\n",
    "\n",
    "## Dense Passage Retriever\n",
    "\n",
    "Now, when we searched through our Elasticsearch document store, we tested two different retrievers - TF-IDF and BM25. Both of these retrievers are referred to as *'sparse retrievers'*. Called sparse as they are using *sparse* vectors (vectors which are built of mostly zero/near-zero values). Alternatively, we have **dense retrievers**, which deal with *dense* vectors, which are packed full of relevant information (unlike sparse with their sparsely concentrated packets of information). We will be using a **Dense Passage Retriever (DPR)** alongside FAISS to retrieve relevant contexts.\n",
    "\n",
    "It is this combination of **Document Store (FAISS)** and **Retriever (DPR)** that we will be building in the next few sections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
