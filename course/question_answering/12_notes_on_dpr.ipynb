{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "referenced-supervisor",
   "metadata": {},
   "source": [
    "# Notes on DPR\n",
    "\n",
    "Our **Dense Passage Retriever (DPR)** model is doing more than just performing a similarity search. Before even filtering through FAISS for relevant contexts, DPR is converting the question you have provided into an *estimated answer*.\n",
    "\n",
    "DPR does not save data like FAISS, and so we can think of the transformation it performs as a *linguistic* exercise. The model takes a question, and based on it's knowledge of question-answer pairs, converts this into a best-guess answer approximation.\n",
    "\n",
    "If we took the question *\"What is the capital of France?\"*, DPR would return something like *\"The capital of France is _\"*. Here, DPR has produced the linguistic *answer*, but excluded any external information that would be required to actually answer the question - DPR doesn't know anything about geography or countries - but it does know language very well.\n",
    "\n",
    "Now, if we take our approximate answer of *\"The capital of France is _\"*, and performed a similarity search in our FAISS index, the closest matching contexts will be returned. The closest matching contexts to *\"The capital of France is _\"* are all very likely to be something similiar to *\"The capital of France is Paris\"*.\n",
    "\n",
    "And this is how DPR works. DPR contains no external knowledge. It maps questions to *approximate answers*. DPR then filters through our FAISS index and identifies the closest similarity contexts to the approximate answer, and returns this to us.\n",
    "\n",
    "The final step, which we will be moving onto next is the extraction of an *exact answer* from the returned contexts. The reason we need this is because our contexts can be very long (~500 words). So our final step is to use a **reader** model to identify the answer within the context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
